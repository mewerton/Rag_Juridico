import os
os.environ["STREAMLIT_WATCHER_PATCHED_MODULES"] = "torch"
import streamlit as st


from rag_pipeline import process_document

# TÃ­tulo do projeto
st.set_page_config(page_title="RAG JurÃ­dico", layout="wide")
st.title("ğŸ“š RAG JurÃ­dico")
st.title("AnÃ¡lise de Documentos JurÃ­dicos")

# Inicializar o session_state para guardar o RAG chain
if "rag_chain" not in st.session_state:
    st.session_state.rag_chain = None

if "document_path" not in st.session_state:
    st.session_state.document_path = None

# Upload do documento
uploaded_file = st.file_uploader("ğŸ“ Envie um documento jurÃ­dico em PDF", type=["pdf"])

if uploaded_file is not None:
    # Garantir que o diretÃ³rio existe
    os.makedirs("data/documentos", exist_ok=True)
    
    # Salvar o arquivo na pasta data/documentos/
    file_path = os.path.join("data", "documentos", uploaded_file.name)
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    st.success(f"âœ… Documento '{uploaded_file.name}' salvo com sucesso!")

    # Guardar o caminho no session_state
    st.session_state.document_path = file_path

    # Mostrar botÃ£o para processar o documento
    if st.button("ğŸ” Analisar documento"):
        with st.spinner("Processando o documento, aguarde... â³"):
            # Processar o documento usando a pipeline
            st.session_state.rag_chain = process_document(file_path)
        st.success("âœ… Documento processado com sucesso! Agora vocÃª pode fazer perguntas.")

# Separador
st.divider()

# Campo de pergunta
st.subheader("ğŸ¤– Pergunte algo sobre o documento:")

if st.session_state.rag_chain:
    pergunta = st.text_input("Digite sua pergunta aqui...")

    if pergunta:
        with st.spinner("Consultando o documento... ğŸ¤–"):
            resposta = st.session_state.rag_chain.invoke({"input": pergunta})
            st.subheader("ğŸ“„ Resposta da IA:")
            st.write(resposta["answer"])
else:
    st.info("ğŸ“ FaÃ§a o upload e anÃ¡lise de um documento para poder perguntar.")