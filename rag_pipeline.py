import os
from typing import List

import streamlit as st
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document as LCDocument
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents.stuff import create_stuff_documents_chain
from langchain.chains.retrieval import create_retrieval_chain

from langchain_docling import DoclingLoader
from langchain_docling.loader import ExportType

# Configura√ß√µes
DATA_FOLDER = "data"
DOCUMENTS_FOLDER = os.path.join(DATA_FOLDER, "documentos")
INDEX_FOLDER = os.path.join(DATA_FOLDER, "indexes")
EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-large"
LLM_MODEL_NAME = "llama3-8b-8192"

# Fun√ß√£o: carregar documento com DoclingLoader (oficial)
def load_documents_with_docling(file_path: str, export_type=ExportType.DOC_CHUNKS) -> List[LCDocument]:
    """Carrega documentos estruturados de v√°rios formatos usando DoclingLoader."""
    loader = DoclingLoader(
        file_path=file_path,
        export_type=export_type
    )
    documents = loader.load()
    return documents

# ‚úÖ Novo: adiciona prefixo "passage:" ao conte√∫do dos documentos
def prefix_documents_for_e5(documents: List[LCDocument]) -> List[LCDocument]:
    """Adiciona prefixo 'passage:' no conte√∫do dos documentos (necess√°rio para E5 embeddings)."""
    for doc in documents:
        doc.page_content = f"passage: {doc.page_content.strip()}"
    return documents

# Fun√ß√£o: opcional ‚Äî re-chunk se necess√°rio
def split_text_into_chunks(documents: List[LCDocument]) -> List[LCDocument]:
    """Divide documentos em chunks menores para melhor performance do embedding."""
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    return text_splitter.split_documents(documents)

# Fun√ß√£o: criar ou carregar vetorstore FAISS
def create_or_load_vectorstore(file_path: str, documents: List[LCDocument], embeddings: HuggingFaceEmbeddings) -> FAISS:
    """Cria ou carrega um √≠ndice vetorial FAISS com os documentos processados."""
    base_filename = os.path.splitext(os.path.basename(file_path))[0]
    index_path = os.path.join(INDEX_FOLDER, f"{base_filename}_faiss_index")

    os.makedirs(INDEX_FOLDER, exist_ok=True)

    if os.path.exists(index_path):
        vectorstore = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
    else:
        vectorstore = FAISS.from_documents(documents, embeddings)
        if os.path.exists(index_path):
            import shutil
            shutil.rmtree(index_path, ignore_errors=True)
        vectorstore.save_local(index_path)

    return vectorstore

# Fun√ß√£o: criar RAG Chain com LangChain
def create_rag_chain(vectorstore: FAISS) -> object:
    """Cria a RAG chain conectando vetorstore e LLM (Groq + Llama3)."""
    retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={"k": 10})

    llm = ChatGroq(
        temperature=0.1,
        model_name=LLM_MODEL_NAME,
        api_key=st.secrets["GROQ_API_KEY"]
    )

    template = """
    Voc√™ √© um assistente jur√≠dico especializado. Analise cuidadosamente o seguinte contexto extra√≠do de documentos jur√≠dicos e responda de forma objetiva, sem adicionar informa√ß√µes externas.

    Se n√£o souber a resposta, diga "N√£o encontrei informa√ß√µes suficientes no documento."

    <context>
    {context}
    </context>

    Pergunta: {input}

    Resposta:
    """
    prompt = ChatPromptTemplate.from_template(template)

    document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)
    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    return retrieval_chain

# Fun√ß√£o principal: processar o documento
def process_document(file_path: str) -> object:
    """Pipeline completo: l√™ o documento, cria vetorstore e prepara a RAG chain."""
    documents = load_documents_with_docling(file_path)
    documents = prefix_documents_for_e5(documents)  # üîß Adiciona o prefixo necess√°rio para o modelo E5
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)
    vectorstore = create_or_load_vectorstore(file_path, documents, embeddings)
    rag_chain = create_rag_chain(vectorstore)
    return rag_chain
